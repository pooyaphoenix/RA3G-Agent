Medical information must be shared only with patient consent.
Do not provide personal or confidential data in public channels.
AI systems must not generate medical diagnoses without verification.
Always verify facts before making scientific claims.
Ethical use of AI includes transparency and accountability.
Personal information should not be collected without user permission.
Discrimination based on race, gender, or religion is prohibited.
Do not disclose passwords, ID numbers, or financial data.
Medical data must comply with HIPAA privacy standards.
AI must respect human autonomy and dignity.
Scientific claims must be supported by evidence.
Misleading medical advice can cause harm.
Users must be informed when interacting with AI systems.
Data encryption ensures security of sensitive records.
Sharing fake medical news can endanger lives.
AI models should not promote self-harm or illegal actions.
All medical advice should come from licensed professionals.
AI output must align with established ethical frameworks.
No personal identifiers should be stored in logs.
Research involving humans must undergo ethical review.
AI-generated text should avoid suggesting unapproved treatments.
The system must block any personally identifiable information.
Safety and privacy are fundamental principles of responsible AI.
AI systems must respect copyright and intellectual property laws.
Unauthorized access to medical databases is prohibited.
AI should help humans make better decisions, not replace them.
Avoid sharing patient photos or imaging results without consent.
Governance ensures compliance with laws and safety policies.
Security audits should be performed regularly.
Never expose internal API keys or credentials.
Model responses must undergo moderation for safety.
Training datasets must exclude harmful or illegal content.
Personal health data should remain private.
Ensure fairness, reliability, and robustness in AI operations.
AI must avoid promoting discrimination or misinformation.
AI decisions should always be explainable to humans.
Sensitive datasets must be anonymized before use.
Consent is required before using human data for training.
Biometric data must be securely stored and encrypted.
AI output must follow medical and scientific guidelines.
An AI system should report uncertainty in its responses.
Developers are responsible for ethical deployment of AI.
Model bias must be continuously monitored and mitigated.
Research ethics demand honesty and transparency.
Medical governance prevents patient data misuse.
AI should promote health literacy and safety.
Medical information must be shared only with patient consent.
Do not provide personal or confidential data in public channels.
AI systems must not generate medical diagnoses without verification.
Always verify facts before making scientific claims.
Ethical use of AI includes transparency and accountability.
Personal information should not be collected without user permission.
Discrimination based on race, gender, or religion is prohibited.
Do not disclose passwords, ID numbers, or financial data.
Medical data must comply with HIPAA privacy standards.
AI must respect human autonomy and dignity.
Scientific claims must be supported by evidence.
Misleading medical advice can cause harm.
Users must be informed when interacting with AI systems.
Data encryption ensures security of sensitive records.
Sharing fake medical news can endanger lives.
AI models should not promote self-harm or illegal actions.
All medical advice should come from licensed professionals.
AI output must align with established ethical frameworks.
No personal identifiers should be stored in logs.
Research involving humans must undergo ethical review.
AI-generated text should avoid suggesting unapproved treatments.
The system must block any personally identifiable information.
Safety and privacy are fundamental principles of responsible AI.
AI systems must respect copyright and intellectual property laws.
Unauthorized access to medical databases is prohibited.
AI should help humans make better decisions, not replace them.
Avoid sharing patient photos or imaging results without consent.
Governance ensures compliance with laws and safety policies.
Security audits should be performed regularly.
Never expose internal API keys or credentials.
Model responses must undergo moderation for safety.
Training datasets must exclude harmful or illegal content.
Personal health data should remain private.
Ensure fairness, reliability, and robustness in AI operations.
AI must avoid promoting discrimination or misinformation.
AI decisions should always be explainable to humans.
Sensitive datasets must be anonymized before use.
Consent is required before using human data for training.
Biometric data must be securely stored and encrypted.
AI output must follow medical and scientific guidelines.
An AI system should report uncertainty in its responses.
Developers are responsible for ethical deployment of AI.
Model bias must be continuously monitored and mitigated.
Research ethics demand honesty and transparency.
Medical governance prevents patient data misuse.
AI should promote health literacy and safety.